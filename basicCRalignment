#!/bin/bash
## SLURM parameters
#SBATCH --time 3-0  # days-minutes
#SBATCH --job-name=D120_etoh3_CTL # Job name
#SBATCH --account=fc_jbscseq
#SBATCH --nodes=1
#SBATCH --ntasks=20 # Number of cores
#SBATCH --mem=64000 # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --partition=savio # Partition to submit to
#SBATCH --qos=savio_normal
#SBATCH --output=countArrayJob_%A_%a.out # File to which STDOUT will be written
#SBATCH --error=countArrayJob_%A_%a.err # File to which STDERR will be written

## Record the start time
start=`date +%s`
## Record the host being run on
hostname

##making sure the path is set
export PATH=/global/scratch/johnblair/opt/cellranger-2.1.1:$PATH

## Set the number of theads and max memory,
##  either determined from Slurm or set yourself if running on command line
THREADS=${SLURM_NTASKS}
MEM=$(expr ${SLURM_MEM_PER_NODE} / 1024)
echo "Slurm job id: " $SLURM_JOB_ID
echo "Allocated threads: " $THREADS
echo "Allocated memory: " $MEM

## nd line, need to set to the row # of the sample to be run 

## https://support.10xgenomics.com/single-cell-gene-expression/software/overview/welcome
## Create the call
cellranger count \
--id= SampleID \
--fastqs= Full/Path/to/GZippedFastQs \
--sample= FASTQsetname \
--transcriptome=/global/scratch/johnblair/newref/newref_Ai9
